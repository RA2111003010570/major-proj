{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPLKlLZl4rwtB8TwoqX63Xh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RA2111003010570/major-proj/blob/main/MAJOR_PROJ.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, LSTM, Dense, Flatten, Dropout, MaxPooling1D, Reshape, Bidirectional, BatchNormalization, LeakyReLU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "metadata": {
        "id": "VclxrcDaA84w"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGRMOHDuBDT3",
        "outputId": "8989343c-b3ea-4144-9e22-5565398ec961"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/tourism_demand1.csv')"
      ],
      "metadata": {
        "id": "L0KjRWi4BIRP"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if 'place' in df.columns:\n",
        "    df.drop(columns=['place'], inplace=True)  # Drop non-numeric columns if present\n",
        "\n",
        "# Handle missing values\n",
        "df.fillna(method='ffill', inplace=True)  # Forward fill missing values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBBG4DAkBQuL",
        "outputId": "0c60998d-57ba-4730-8721-805869836a94"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-2a1f9689b1fd>:5: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  df.fillna(method='ffill', inplace=True)  # Forward fill missing values\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.replace({'#VALUE!': np.nan,  # Replace '#VALUE!' with NaN\n",
        "                   '': np.nan,           # Add any other strings as needed\n",
        "                   ' ': np.nan,\n",
        "                  }, regex=False)"
      ],
      "metadata": {
        "id": "36urTLYeBrqv"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['month'] = pd.to_datetime(df.iloc[:, 0], format='your_date_format', errors='coerce').dt.month\n",
        "df['year'] = pd.to_datetime(df.iloc[:, 0], format='your_date_format', errors='coerce').dt.year"
      ],
      "metadata": {
        "id": "eEPBhWw5CCQ3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sequences(data, seq_length):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - seq_length):\n",
        "        X.append(data[i:i + seq_length])\n",
        "        y.append(data[i + seq_length])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "seq_length = 12  # Use past 12 months to predict next month\n",
        "X, y = create_sequences(data_scaled, seq_length)"
      ],
      "metadata": {
        "id": "JY_CqPovCGYm"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(len(X) * 0.8)\n",
        "X_train, X_test = X[:train_size], X[train_size:]\n",
        "y_train, y_test = y[:train_size], y[train_size:]"
      ],
      "metadata": {
        "id": "2vehLEz_CJ6Q"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], X_train.shape[2]))  # Remove last dimension\n",
        "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], X_test.shape[2]))  # Remove last dimension\n"
      ],
      "metadata": {
        "id": "x1yXm1d3CMkK"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.layers import Conv1D, LSTM, Dense, Dropout, MaxPooling1D, Bidirectional, BatchNormalization, LeakyReLU\n",
        "\n",
        "model = Sequential([\n",
        "    # CNN Block\n",
        "    Conv1D(filters=64, kernel_size=3, activation='relu', padding='same', input_shape=(seq_length, X_train.shape[2])),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling1D(pool_size=2, padding='same'),\n",
        "\n",
        "    # Ensure correct LSTM input shape\n",
        "    Bidirectional(LSTM(64, return_sequences=True)),\n",
        "    LSTM(32, return_sequences=False),\n",
        "    Dropout(0.4),\n",
        "\n",
        "    # Fully Connected Layers\n",
        "    Dense(32, activation=LeakyReLU(alpha=0.1), kernel_regularizer=l2(0.01)),\n",
        "    Dense(y.shape[1])  # Output layer\n",
        "])\n"
      ],
      "metadata": {
        "id": "r8jBF3C2JsRn"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='mae')"
      ],
      "metadata": {
        "id": "JMKcTk0WCxOy"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), verbose=1, callbacks=[early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duDwlqnmC1de",
        "outputId": "eb932868-d8bf-4735-b844-d59db23a5cb2"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 182ms/step - loss: 0.3507 - val_loss: 0.3261\n",
            "Epoch 2/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.3247 - val_loss: 0.3086\n",
            "Epoch 3/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.3122 - val_loss: 0.2940\n",
            "Epoch 4/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.2915 - val_loss: 0.2801\n",
            "Epoch 5/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.2760 - val_loss: 0.2670\n",
            "Epoch 6/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.2624 - val_loss: 0.2548\n",
            "Epoch 7/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.2520 - val_loss: 0.2434\n",
            "Epoch 8/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.2376 - val_loss: 0.2324\n",
            "Epoch 9/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.2266 - val_loss: 0.2210\n",
            "Epoch 10/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.2132 - val_loss: 0.2099\n",
            "Epoch 11/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.2041 - val_loss: 0.2003\n",
            "Epoch 12/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.1941 - val_loss: 0.1912\n",
            "Epoch 13/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.1825 - val_loss: 0.1823\n",
            "Epoch 14/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.1742 - val_loss: 0.1733\n",
            "Epoch 15/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.1657 - val_loss: 0.1646\n",
            "Epoch 16/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.1579 - val_loss: 0.1564\n",
            "Epoch 17/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.1496 - val_loss: 0.1490\n",
            "Epoch 18/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.1424 - val_loss: 0.1425\n",
            "Epoch 19/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.1344 - val_loss: 0.1359\n",
            "Epoch 20/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.1296 - val_loss: 0.1292\n",
            "Epoch 21/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.1217 - val_loss: 0.1228\n",
            "Epoch 22/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.1171 - val_loss: 0.1169\n",
            "Epoch 23/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.1112 - val_loss: 0.1114\n",
            "Epoch 24/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.1045 - val_loss: 0.1066\n",
            "Epoch 25/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0996 - val_loss: 0.1014\n",
            "Epoch 26/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0950 - val_loss: 0.0965\n",
            "Epoch 27/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0895 - val_loss: 0.0918\n",
            "Epoch 28/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0848 - val_loss: 0.0876\n",
            "Epoch 29/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0810 - val_loss: 0.0835\n",
            "Epoch 30/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0763 - val_loss: 0.0791\n",
            "Epoch 31/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0738 - val_loss: 0.0753\n",
            "Epoch 32/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0695 - val_loss: 0.0725\n",
            "Epoch 33/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0655 - val_loss: 0.0696\n",
            "Epoch 34/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0622 - val_loss: 0.0663\n",
            "Epoch 35/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0608 - val_loss: 0.0628\n",
            "Epoch 36/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0551 - val_loss: 0.0600\n",
            "Epoch 37/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0528 - val_loss: 0.0575\n",
            "Epoch 38/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0509 - val_loss: 0.0551\n",
            "Epoch 39/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0472 - val_loss: 0.0525\n",
            "Epoch 40/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0459 - val_loss: 0.0497\n",
            "Epoch 41/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0441 - val_loss: 0.0472\n",
            "Epoch 42/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0403 - val_loss: 0.0456\n",
            "Epoch 43/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0404 - val_loss: 0.0444\n",
            "Epoch 44/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0366 - val_loss: 0.0423\n",
            "Epoch 45/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0359 - val_loss: 0.0402\n",
            "Epoch 46/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0326 - val_loss: 0.0387\n",
            "Epoch 47/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0319 - val_loss: 0.0374\n",
            "Epoch 48/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0300 - val_loss: 0.0359\n",
            "Epoch 49/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0319 - val_loss: 0.0341\n",
            "Epoch 50/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0294 - val_loss: 0.0324\n",
            "Epoch 51/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0260 - val_loss: 0.0316\n",
            "Epoch 52/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0252 - val_loss: 0.0310\n",
            "Epoch 53/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0245 - val_loss: 0.0301\n",
            "Epoch 54/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0242 - val_loss: 0.0287\n",
            "Epoch 55/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0238 - val_loss: 0.0273\n",
            "Epoch 56/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0207 - val_loss: 0.0263\n",
            "Epoch 57/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0206 - val_loss: 0.0258\n",
            "Epoch 58/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0215 - val_loss: 0.0251\n",
            "Epoch 59/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0201 - val_loss: 0.0247\n",
            "Epoch 60/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0207 - val_loss: 0.0238\n",
            "Epoch 61/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0183 - val_loss: 0.0231\n",
            "Epoch 62/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0175 - val_loss: 0.0224\n",
            "Epoch 63/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0164 - val_loss: 0.0218\n",
            "Epoch 64/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0158 - val_loss: 0.0214\n",
            "Epoch 65/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0162 - val_loss: 0.0205\n",
            "Epoch 66/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0147 - val_loss: 0.0200\n",
            "Epoch 67/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0152 - val_loss: 0.0199\n",
            "Epoch 68/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0133 - val_loss: 0.0198\n",
            "Epoch 69/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0135 - val_loss: 0.0194\n",
            "Epoch 70/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0138 - val_loss: 0.0183\n",
            "Epoch 71/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0148 - val_loss: 0.0179\n",
            "Epoch 72/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0133 - val_loss: 0.0177\n",
            "Epoch 73/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0123 - val_loss: 0.0177\n",
            "Epoch 74/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0128 - val_loss: 0.0175\n",
            "Epoch 75/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0125 - val_loss: 0.0172\n",
            "Epoch 76/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0119 - val_loss: 0.0168\n",
            "Epoch 77/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0110 - val_loss: 0.0164\n",
            "Epoch 78/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0126 - val_loss: 0.0162\n",
            "Epoch 79/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0103 - val_loss: 0.0164\n",
            "Epoch 80/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0107 - val_loss: 0.0162\n",
            "Epoch 81/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0106 - val_loss: 0.0159\n",
            "Epoch 82/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0098 - val_loss: 0.0157\n",
            "Epoch 83/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0094 - val_loss: 0.0153\n",
            "Epoch 84/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0109 - val_loss: 0.0152\n",
            "Epoch 85/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0097 - val_loss: 0.0152\n",
            "Epoch 86/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0104 - val_loss: 0.0152\n",
            "Epoch 87/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0093 - val_loss: 0.0151\n",
            "Epoch 88/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0101 - val_loss: 0.0147\n",
            "Epoch 89/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0092 - val_loss: 0.0144\n",
            "Epoch 90/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0096 - val_loss: 0.0147\n",
            "Epoch 91/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0099 - val_loss: 0.0149\n",
            "Epoch 92/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0103 - val_loss: 0.0149\n",
            "Epoch 93/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0096 - val_loss: 0.0146\n",
            "Epoch 94/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0086 - val_loss: 0.0144\n",
            "Epoch 95/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0085 - val_loss: 0.0143\n",
            "Epoch 96/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0084 - val_loss: 0.0147\n",
            "Epoch 97/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0106 - val_loss: 0.0146\n",
            "Epoch 98/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0090 - val_loss: 0.0143\n",
            "Epoch 99/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0073 - val_loss: 0.0140\n",
            "Epoch 100/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0091 - val_loss: 0.0139\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sABd1m0tD5GC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Assuming 'df' is your DataFrame and 'numerical_cols' are the columns you want to predict\n",
        "# ... (your previous code) ...\n",
        "\n",
        "# Initialize the scaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Check if the target columns are present in the DataFrame\n",
        "target_cols = ['Domestic-2019-20', 'Foreign-2019-20', 'Revenue-2019-20', 'AvgRevenue-2019-20']  # Replace with your actual target columns if different\n",
        "\n",
        "# Filter out non-existent columns from target_cols\n",
        "existing_target_cols = [col for col in target_cols if col in df.columns]\n",
        "\n",
        "if existing_target_cols:  # Proceed only if there are existing target columns\n",
        "    # Fit the scaler on the training data only for the existing target columns\n",
        "    scaler.fit(df.loc[:train_size, existing_target_cols]) # Fit on training data for target columns\n",
        "\n",
        "    # Transform both training and testing targets\n",
        "    df.loc[:, existing_target_cols] = scaler.transform(df.loc[:, existing_target_cols])\n",
        "else:\n",
        "    print(\"Error: No target columns found in DataFrame. Scaling skipped.\")\n",
        "\n",
        "# ... (the rest of your code, including create_sequences and model training) ...\n",
        "\n",
        "# After making predictions\n",
        "# (Ensure y_pred and y_test have the same number of columns as existing_target_cols)\n",
        "if existing_target_cols:\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Reshape to match the number of existing target columns\n",
        "    y_pred = y_pred.reshape(-1, len(existing_target_cols))\n",
        "    y_pred = scaler.inverse_transform(y_pred)\n",
        "\n",
        "    y_test = y_test.reshape(-1, len(existing_target_cols))\n",
        "    y_test = scaler.inverse_transform(y_test)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rprg4r3cEuIn",
        "outputId": "2d4fe362-2284-4edc-fee7-bf32fcd7a889"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 490ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xo06abUMHYjy",
        "outputId": "34c15f91-80b1-4c28-ac0e-c398dec8c44a"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = y_pred.reshape(y_test.shape)"
      ],
      "metadata": {
        "id": "6L2iSwNLICCh"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_pred = np.zeros((y_pred.shape[0], data_scaled.shape[1]))  # Match original scaled data shape\n",
        "temp_test = np.zeros((y_test.shape[0], data_scaled.shape[1]))"
      ],
      "metadata": {
        "id": "aG1nQyX4He6C"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_pred[:, -y_pred.shape[1]:] = y_pred\n",
        "temp_test[:, -y_test.shape[1]:] = y_test\n"
      ],
      "metadata": {
        "id": "q8_1B6aMHiby"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "JeQsBsbjIdli"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"MAE: {mae:.2f}\")\n",
        "print(f\"MSE: {mse:.2f}\")\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "print(f\"R² Score: {r2:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CarEGxNNIepm",
        "outputId": "79560661-8c59-4cf6-a14f-76b733441eba"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE: 0.01\n",
            "MSE: 0.00\n",
            "RMSE: 0.06\n",
            "R² Score: -0.05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
        "print(f\"MAPE: {mape:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdokcyuZIyM5",
        "outputId": "3c93a803-808a-47dd-9c8a-63c7b892aa42"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAPE: inf%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-52-a486dfcd9d68>:1: RuntimeWarning: divide by zero encountered in divide\n",
            "  mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_pred = np.mean(y_train, axis=0)\n",
        "baseline_mse = mean_squared_error(y_test, np.tile(baseline_pred, (y_test.shape[0], 1)))\n",
        "print(f\"Baseline MSE: {baseline_mse:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ni1Zi6cqI6Fl",
        "outputId": "7e9402a7-8bbc-4510-f044-96af7ec5bc23"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline MSE: 0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure y_pred has the correct shape\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Reshape y_pred to match y_test\n",
        "y_pred = y_pred.reshape(y_test.shape)\n",
        "\n",
        "# Create a temporary array with the same number of columns as the scaler was fitted on\n",
        "# This should match the number of target columns (existing_target_cols)\n",
        "temp_pred = np.zeros((len(y_pred), len(existing_target_cols)))\n",
        "temp_test = np.zeros((len(y_test), len(existing_target_cols)))\n",
        "\n",
        "# Assign predictions to the temporary array\n",
        "temp_pred = y_pred\n",
        "temp_test = y_test\n",
        "\n",
        "# Apply inverse transformation\n",
        "temp_pred = scaler.inverse_transform(temp_pred)  # Now shapes should match\n",
        "temp_test = scaler.inverse_transform(temp_test)\n",
        "\n",
        "# Assign the inverse-transformed values back to y_pred and y_test\n",
        "y_pred = temp_pred\n",
        "y_test = temp_test\n",
        "\n",
        "# Evaluate Performance\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"MAE: {mae:.2f}\")\n",
        "print(f\"MSE: {mse:.2f}\")\n",
        "print(f\"RMSE: {rmse:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBLSb_pwK1k1",
        "outputId": "4e6ba4c9-3ae6-4cfc-db4c-eb969a537815"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "MAE: 0.01\n",
            "MSE: 0.00\n",
            "RMSE: 0.06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(y_test, label='Actual')\n",
        "plt.plot(y_pred, label='Predicted')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "p5NhXNnELRfD",
        "outputId": "af5eb9b0-58eb-4176-86ab-53e8d8bcbf24"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcdErUTaMRUz",
        "outputId": "3eff1345-debc-4f9c-880b-d3fd5e9368a7"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 0.06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Reshape X_train and X_test to 2D for RandomForestRegressor\n",
        "X_train_rf = X_train.reshape(X_train.shape[0], -1)  # Flatten time steps and features\n",
        "X_test_rf = X_test.reshape(X_test.shape[0], -1)    # Flatten time steps and features\n",
        "\n",
        "# Initialize Random Forest model\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the model on training data\n",
        "rf_model.fit(X_train_rf, y_train)  # Use reshaped X_train\n",
        "\n",
        "# Make predictions\n",
        "y_pred_rf = rf_model.predict(X_test_rf)  # Use reshaped X_test\n",
        "\n",
        "# Reshape predictions to match actual labels\n",
        "y_pred_rf = y_pred_rf.reshape(y_test.shape)\n",
        "\n",
        "# Calculate MAE\n",
        "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
        "\n",
        "# Calculate RMSE\n",
        "rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
        "\n",
        "# Calculate R² Score\n",
        "r2_rf = r2_score(y_test, y_pred_rf)\n",
        "\n",
        "# Print Results\n",
        "print(f\"🌲 Random Forest MAE: {mae_rf:.4f}\")\n",
        "print(f\"🌲 Random Forest RMSE: {rmse_rf:.4f}\")\n",
        "print(f\"🌲 Random Forest R² Score: {r2_rf:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucxomSrPNU3t",
        "outputId": "2477503a-bbed-4580-819f-30e29d36db21"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🌲 Random Forest MAE: 0.0153\n",
            "🌲 Random Forest RMSE: 0.0322\n",
            "🌲 Random Forest R² Score: -5.6683\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xgboost\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming X and y are your features and target variables\n",
        "# Reshape X to 2D before splitting\n",
        "X_2D = X.reshape(X.shape[0], -1)  # Reshape to (samples, timesteps * features)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_2D, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define XGBoost model\n",
        "model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions (reshape X_test to 2D as well)\n",
        "y_pred = model.predict(X_test.reshape(X_test.shape[0], -1))\n",
        "\n",
        "# Calculate MAE\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "# Calculate RMSE\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "\n",
        "print(f\"XGBoost MAE: {mae:.2f}\")\n",
        "print(f\"XGBoost RMSE: {rmse:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d05XFbuFOHPk",
        "outputId": "4432891f-e9ec-4bec-9d25-a280ecd7641b"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.26.4)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.13.1)\n",
            "XGBoost MAE: 0.01\n",
            "XGBoost RMSE: 0.03\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Make predictions using the trained CNN model\n",
        "# Reshape X_test to have the expected 3D shape\n",
        "# Reshape X_test to match the expected input shape for the CNN\n",
        "# Get the original shape of X before flattening\n",
        "original_shape = X.shape\n",
        "\n",
        "# Reshape X_test based on the original shape\n",
        "X_test = X_test.reshape((X_test.shape[0], original_shape[1], original_shape[2]))\n",
        "\n",
        "# Make predictions using the trained CNN model\n",
        "y_pred_cnn = model.predict(X_test)\n",
        "\n",
        "# ... (rest of your code)\n",
        "\n",
        "# Calculate RMSE\n",
        "rmse_cnn = np.sqrt(mean_squared_error(y_test, y_pred_cnn))\n",
        "\n",
        "# Calculate R² Score\n",
        "r2_cnn = r2_score(y_test, y_pred_cnn)\n",
        "\n",
        "# Print Results\n",
        "print(f\"✅ CNN RMSE: {rmse_cnn:.4f}\")\n",
        "print(f\"✅ CNN R² Score: {r2_cnn:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcqJdDDuO8Be",
        "outputId": "414355b3-eb61-4492-a19f-021bb216bab3"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "✅ CNN RMSE: 0.0232\n",
            "✅ CNN R² Score: -0.1735\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Make predictions using the trained LSTM model\n",
        "y_pred_lstm = model.predict(X_test)\n",
        "\n",
        "# Reshape predictions to match the actual test labels\n",
        "y_pred_lstm = y_pred_lstm.reshape(y_test.shape)\n",
        "\n",
        "# Calculate MAE\n",
        "mae_lstm = mean_absolute_error(y_test, y_pred_lstm)\n",
        "\n",
        "# Calculate RMSE\n",
        "rmse_lstm = np.sqrt(mean_squared_error(y_test, y_pred_lstm))\n",
        "\n",
        "# Calculate R² Score\n",
        "r2_lstm = r2_score(y_test, y_pred_lstm)\n",
        "\n",
        "# Print Results\n",
        "print(f\"✅ LSTM MAE: {mae_lstm:.4f}\")\n",
        "print(f\"✅ LSTM RMSE: {rmse_lstm:.4f}\")\n",
        "print(f\"✅ LSTM R² Score: {r2_lstm:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tv1ggW2FRdNE",
        "outputId": "787c6622-52b1-41ca-beb3-05cd0b063cbb"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "✅ LSTM MAE: 0.0075\n",
            "✅ LSTM RMSE: 0.0232\n",
            "✅ LSTM R² Score: -0.1735\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Dense(5)  # Instead of Dense(1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Igpu065lUjj5",
        "outputId": "02d1e521-44e0-48c7-e12d-9c889446df03"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Dense name=dense_28, built=False>"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Splitting Data (Assuming X, y are defined)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Reshape X for CNN (Ensure 3D input shape: (samples, timesteps, features))\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], X_train.shape[2]))\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], X_test.shape[2]))\n",
        "\n",
        "# CNN Model (Modified for 5 Outputs)\n",
        "cnn_model = Sequential([\n",
        "    Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(y_train.shape[1])  # Ensure output matches y_train.shape[1] (5 outputs)\n",
        "])\n",
        "\n",
        "cnn_model.compile(optimizer='adam', loss='mse')\n",
        "cnn_model.fit(X_train, y_train, epochs=50, batch_size=16, verbose=1)\n",
        "\n",
        "# Predictions\n",
        "y_pred_cnn = cnn_model.predict(X_test)\n",
        "\n",
        "# Compute MAE & RMSE for CNN\n",
        "cnn_mae = mean_absolute_error(y_test, y_pred_cnn)\n",
        "cnn_rmse = np.sqrt(mean_squared_error(y_test, y_pred_cnn))\n",
        "\n",
        "print(f\"CNN MAE: {cnn_mae:.2f}\")\n",
        "print(f\"CNN RMSE: {cnn_rmse:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_bpGi5DUkvm",
        "outputId": "96ce0529-1cc7-4f7f-92f9-85921594813d"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0076\n",
            "Epoch 2/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0064 \n",
            "Epoch 3/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0108 \n",
            "Epoch 4/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0080     \n",
            "Epoch 5/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0050     \n",
            "Epoch 6/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0052     \n",
            "Epoch 7/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0080 \n",
            "Epoch 8/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0069     \n",
            "Epoch 9/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0172 \n",
            "Epoch 10/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0175 \n",
            "Epoch 11/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0042     \n",
            "Epoch 12/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0063     \n",
            "Epoch 13/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0064 \n",
            "Epoch 14/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0087      \n",
            "Epoch 15/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0097 \n",
            "Epoch 16/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0037     \n",
            "Epoch 17/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0077  \n",
            "Epoch 18/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0066 \n",
            "Epoch 19/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0169 \n",
            "Epoch 20/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0097     \n",
            "Epoch 21/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0167 \n",
            "Epoch 22/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0034     \n",
            "Epoch 23/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0029     \n",
            "Epoch 24/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0032     \n",
            "Epoch 25/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0039 \n",
            "Epoch 26/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0103     \n",
            "Epoch 27/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0029     \n",
            "Epoch 28/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0064     \n",
            "Epoch 29/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0154  \n",
            "Epoch 30/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0071 \n",
            "Epoch 31/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0063     \n",
            "Epoch 32/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0059     \n",
            "Epoch 33/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0033     \n",
            "Epoch 34/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0056 \n",
            "Epoch 35/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0102     \n",
            "Epoch 36/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0035     \n",
            "Epoch 37/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0041     \n",
            "Epoch 38/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0063     \n",
            "Epoch 39/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0043 \n",
            "Epoch 40/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0028     \n",
            "Epoch 41/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0034      \n",
            "Epoch 42/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0073     \n",
            "Epoch 43/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0061  \n",
            "Epoch 44/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0094 \n",
            "Epoch 45/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0051 \n",
            "Epoch 46/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0043 \n",
            "Epoch 47/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0048     \n",
            "Epoch 48/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0058     \n",
            "Epoch 49/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0039 \n",
            "Epoch 50/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0067 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 22 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7b2365169120> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
            "CNN MAE: 0.02\n",
            "CNN RMSE: 0.03\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, LSTM, Dropout, Bidirectional\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Splitting Data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "### 1️⃣ CNN Model ###\n",
        "cnn_model = Sequential([\n",
        "    Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(y_train.shape[1])  # Ensure output shape matches y_train\n",
        "])\n",
        "\n",
        "cnn_model.compile(optimizer='adam', loss='mse')\n",
        "cnn_model.fit(X_train, y_train, epochs=50, batch_size=16, verbose=0)\n",
        "y_pred_cnn = cnn_model.predict(X_test)\n",
        "\n",
        "cnn_mae = mean_absolute_error(y_test, y_pred_cnn)\n",
        "cnn_rmse = np.sqrt(mean_squared_error(y_test, y_pred_cnn))\n",
        "\n",
        "\n",
        "### 2️⃣ LSTM Model ###\n",
        "lstm_model = Sequential([\n",
        "    LSTM(50, activation='relu', return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
        "    LSTM(50, activation='relu'),\n",
        "    Dense(50, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(y_train.shape[1])\n",
        "])\n",
        "\n",
        "lstm_model.compile(optimizer='adam', loss='mse')\n",
        "lstm_model.fit(X_train, y_train, epochs=50, batch_size=16, verbose=0)\n",
        "y_pred_lstm = lstm_model.predict(X_test)\n",
        "\n",
        "lstm_mae = mean_absolute_error(y_test, y_pred_lstm)\n",
        "lstm_rmse = np.sqrt(mean_squared_error(y_test, y_pred_lstm))\n",
        "\n",
        "\n",
        "### 3️⃣ Random Forest ###\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train.reshape(X_train.shape[0], -1), y_train)  # Reshape for 2D input\n",
        "y_pred_rf = rf_model.predict(X_test.reshape(X_test.shape[0], -1))\n",
        "\n",
        "rf_mae = mean_absolute_error(y_test, y_pred_rf)\n",
        "rf_rmse = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
        "\n",
        "\n",
        "### 4️⃣ XGBoost ###\n",
        "xgb_model = XGBRegressor(n_estimators=100, random_state=42)\n",
        "xgb_model.fit(X_train.reshape(X_train.shape[0], -1), y_train)  # Reshape for 2D input\n",
        "y_pred_xgb = xgb_model.predict(X_test.reshape(X_test.shape[0], -1))\n",
        "\n",
        "xgb_mae = mean_absolute_error(y_test, y_pred_xgb)\n",
        "xgb_rmse = np.sqrt(mean_squared_error(y_test, y_pred_xgb))\n",
        "\n",
        "\n",
        "### 📊 Create a Table for Comparison ###\n",
        "results_df = pd.DataFrame({\n",
        "    'Model': ['CNN', 'LSTM', 'Random Forest', 'XGBoost'],\n",
        "    'MAE': [cnn_mae, lstm_mae, rf_mae, xgb_mae],\n",
        "    'RMSE': [cnn_rmse, lstm_rmse, rf_rmse, xgb_rmse]\n",
        "})\n",
        "\n",
        "print(results_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHGValhRVBJB",
        "outputId": "d6f7433a-c606-4efb-bc07-481a72e024a5"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 318ms/step\n",
            "           Model       MAE      RMSE\n",
            "0            CNN  0.021603  0.035618\n",
            "1           LSTM  0.015245  0.023150\n",
            "2  Random Forest  0.015310  0.032180\n",
            "3        XGBoost  0.014469  0.037010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Flatten, Dense, Dropout\n",
        "\n",
        "# Assume X and y are already preprocessed feature and target datasets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Hybrid CNN-LSTM Model\n",
        "model = Sequential([\n",
        "    Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    LSTM(50, activation='relu', return_sequences=True),\n",
        "    LSTM(50, activation='relu'),\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(y_train.shape[1])  # Ensure correct output shape\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=16, verbose=0)\n",
        "\n",
        "# Predictions\n",
        "y_pred_hybrid = model.predict(X_test)\n",
        "\n",
        "# Compute MAE & RMSE\n",
        "hybrid_mae = mean_absolute_error(y_test, y_pred_hybrid)\n",
        "hybrid_rmse = np.sqrt(mean_squared_error(y_test, y_pred_hybrid))\n",
        "\n",
        "# Display Results\n",
        "print(f\"Hybrid CNN-LSTM MAE: {hybrid_mae:.4f}\")\n",
        "print(f\"Hybrid CNN-LSTM RMSE: {hybrid_rmse:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPNo1dyOVfKt",
        "outputId": "f435fb62-070d-43de-900d-b378013eec83"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 321ms/step\n",
            "Hybrid CNN-LSTM MAE: 0.0144\n",
            "Hybrid CNN-LSTM RMSE: 0.0234\n"
          ]
        }
      ]
    }
  ]
}